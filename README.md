Question 1:
I would integrate end-to-end tests into a continuous integration (CI) workflow—specifically a GitHub Action that runs on every push to the repository. This setup guarantees tests execute in a clean, consistent environment with the same browser versions and dependencies every time. Having tests run automatically on pull requests enforces quality gates: any failing test blocks merges until the issue is fixed, preventing regressions from reaching shared branches. Automated CI testing also accelerates feedback, catching integration or UI breakages immediately rather than relying on manual triggers. Ultimately, embedding E2E tests in CI aligns with modern DevOps best practices and ensures confidence in each deployment.

Question 2:
No, E2E tests are designed to validate full user workflows, including UI rendering, network calls, and browser-side storage, rather than isolated logic. For verifying a pure function’s return value, unit tests are far more appropriate: they run in isolation, execute in milliseconds, and pinpoint failures directly to the function under test. Unit tests also encourage better code design by promoting modularity and clear interfaces. By reserving E2E tests for high-level scenarios and using unit tests for granular logic checks, you keep your test suite fast, maintainable, and focused on the right level of validation.

Question 3:
In Lighthouse, Navigation mode reloads the page from scratch and measures the entire load process, capturing key performance metrics like First Contentful Paint, Largest Contentful Paint, Total Blocking Time, and Cumulative Layout Shift. Moreover, this mode is ideal when you want to know how quickly a first-time visitor can see and interact with your site. On the other hand, Snapshot mode doesn’t reload the page; it freezes the current state in DevTools and runs only static audits, such as accessibility, best practices, and SEO. Since no network activity occurs, it can’t assess performance or layout shifts, but it’s useful for evaluating specific UI states—like an open modal or a filled shopping cart—without worrying about timing metrics.

Question 4:
My Lighthouse report for the CSE 110 Shop revealed solid scores in accessibility, best practices, and SEO, but performance was noticeably lower. After reviewing the results, I found a few clear areas for improvement. The images used for the products and the homepage banner appear to be larger than necessary, which slows down the initial load. Optimizing these images, by compressing them or using more efficient formats which could help improve load speed. I also noticed that the site relies on a single large JavaScript file that loads early and blocks rendering. This could be improved by breaking the script into smaller, more focused parts, like separating cart-related logic from the product display—and using modern loading strategies like defer or ES modules. Additionally, some of the static files don’t seem to be compressed or cached effectively. Turning on compression and setting better cache policies would reduce how much data needs to be transferred, especially on repeat visits. Addressing these issues would not only raise the performance score but also create a noticeably smoother experience for users.